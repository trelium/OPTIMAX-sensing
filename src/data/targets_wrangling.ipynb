{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants questionnaire data \n",
    "at location  /opt/data/optimax_sensing/Klinische\\ Variabeln_Gesamt_220120_LA.sav\n",
    "\n",
    "\n",
    "from columns:\n",
    "- OASIS_PRE\t\n",
    "- BAI_PRE\n",
    "- BAI_POST2\n",
    "- OASIS_POST2\n",
    "- BAI_POST\n",
    "- OASIS_POST\n",
    "- BAI_MID2\n",
    "- OASIS_MID2\n",
    "- BAI_MID\n",
    "- OASIS_MID \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "QU_PRE = \"/opt/data/optimax_sensing/unipark/PRE_Klinische Variabeln_Gesamt_220120_LA.csv\"\n",
    "QU_MIDa = \"/opt/data/optimax_sensing/unipark/MID_Gesamtfile_211213_LA.csv\"\n",
    "QU_MIDb = \"/opt/data/optimax_sensing/unipark/MID2_Gesamt_111021_AE.csv\"\n",
    "QU_POSTa = \"/opt/data/optimax_sensing/unipark/Post_Gesamt_20220214_LA.csv\"\n",
    "QU_POSTb = \"/opt/data/optimax_sensing/unipark/POST2_Gesamt_291021_AE.csv\"\n",
    "\n",
    "def create_df(path): \n",
    "    df = pd.read_csv(path,sep = ';')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(QU_PRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "parta = ['p102', 'p104', 'p124', 'p131', 'p134', 'p141', 'p149', 'p154', 'p166', 'p170', 'p181', 'p194', 'p201', 'p208', 'p230', 'p255', 'p261', 'p262', 'p263', 'p265', 'p273', 'p284', 'p310', 'p319', 'p326', 'p333', 'p355', 'p366', 'p369', 'p376', 'p383', 'p393', 'p400']\n",
    "parta = set([int(i[1:]) for i in parta]) #ones in ps dataset \n",
    "\n",
    "missing = parta - set([int(re.findall(r'[0-9]+', i, flags=0)[0]) for i in df['VP']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{101, 102, 104, 105, 106, 107, 109, 113, 114, 115, 116, 117, 118, 121, 123, 124, 128, 129, 130, 131, 133, 134, 135, 136, 137, 140, 141, 142, 146, 147, 149, 150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 168, 169, 170, 171, 173, 174, 175, 177, 178, 179, 181, 182, 184, 186, 188, 189, 190, 194, 195, 196, 197, 198, 199, 200, 201, 204, 207, 208, 210, 213, 214, 215, 216, 217, 218, 219, 220, 226, 227, 229, 230, 233, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 257, 258, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 273, 275, 277, 279, 282, 283, 284, 285, 286, 288, 290, 291, 292, 294, 295, 296, 297, 298, 299, 302, 310, 311, 312, 313, 315, 316, 317, 319, 323, 325, 326, 333, 335, 336, 340, 344, 345, 346, 348, 349, 350, 351, 352, 354, 355, 366, 369, 370, 371, 372, 374, 376, 382, 383, 387, 392, 393, 394, 396, 400, 401, 404, 405, 407, 408, 409, 411, 413, 415, 416, 417, 418, 421, 423, 424, 425, 427, 428, 429, 430, 431, 433, 434, 439, 441, 443, 444, 447, 449, 450, 452, 453, 457, 461, 463, 466, 470, 472, 473, 477, 479, 480, 482, 486, 487, 494, 503, 504}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(set([int(re.findall(r'[0-9]+', i, flags=0)[0]) for i in df['VP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants demographic data \n",
    "at location  /opt/data/optimax_sensing/Klinische\\ Variabeln_Gesamt_220120_LA.sav\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Roche/pyreadstat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants EMA data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "GESAMTFILE_b = '/opt/data/optimax_sensing/Gesamtfile_EMA_Baseline_bereinigt_29.01.22_MD.xlsx'\n",
    "GESAMTFILE_m = '/opt/data/optimax_sensing/Gesamtfile_EMA_MID_29.01.22_MD.xlsx'\n",
    "GESAMTFILE_p = '/opt/data/optimax_sensing/Gesamtfile_EMA_POST_29.01.22_MD.xlsx'\n",
    "\n",
    "def create_df(path):\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "    df = df[['VP','Date_Time_last_action (MAX) / completed (SEMA3)','Teilnehmer Mattermost']]\n",
    "\n",
    "    #Generate placeholder values for missing columns \n",
    "    df[['fitbit_id','empatica_id']] = None\n",
    "    df['platform'] = 'infer'\n",
    "    df['label'] = df['VP']\n",
    "    df['end_date'] = None #df['Date_Time_last_action (MAX) / completed (SEMA3)']\n",
    "\n",
    "    #rename and order columns\n",
    "    df = df[['Teilnehmer Mattermost','fitbit_id','empatica_id','VP','platform','label','Date_Time_last_action (MAX) / completed (SEMA3)','end_date']]\n",
    "    df.columns = ['device_id','fitbit_id','empatica_id','pid','platform','label','start_date','end_date']\n",
    "\n",
    "    #drop NAs in pid column \n",
    "    df = df.dropna(subset=['pid'])\n",
    "    df = df.dropna(subset=['device_id'])\n",
    "\n",
    "    #Convert dtypes\n",
    "    df = df.astype({\"label\": int, \"pid\": int})\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], infer_datetime_format = True)\n",
    "    #df['start_date'] = df['start_date'].dt.round('D') #round to day, yields inaccurate results \n",
    "\n",
    "\n",
    "    #group by participant and get first and last date, put in last two columns \n",
    "    end_dates = df.groupby('pid')['start_date'].max().to_frame()\n",
    "    start_dates = df.groupby('pid')['start_date'].min().to_frame()\n",
    "\n",
    "\n",
    "    df = df.drop_duplicates(subset=['pid']) #delete duplicate rows \n",
    "\n",
    "    df = df.drop(['start_date','end_date'], axis = 1)\n",
    "\n",
    "    df = df.merge(start_dates, how = 'inner', on = ['pid'])\n",
    "    df = df.merge(end_dates, how = 'inner', on = ['pid'])\n",
    "\n",
    "    #rename columns\n",
    "    df.columns = ['device_id','fitbit_id','empatica_id','pid','platform','label','start_date','end_date']\n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0df2cfb84774f0702a5c60597a55428a617a740408e51364ed5b74315eca8fd4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('OptimaxSensing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
