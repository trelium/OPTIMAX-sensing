{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babfddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "GESAMTFILE_b = '/opt/data/optimax_sensing/Gesamtfile_EMA_Baseline_bereinigt_29.01.22_MD.xlsx'\n",
    "GESAMTFILE_m = '/opt/data/optimax_sensing/Gesamtfile_EMA_MID_29.01.22_MD.xlsx'\n",
    "GESAMTFILE_p = '/opt/data/optimax_sensing/Gesamtfile_EMA_POST_29.01.22_MD.xlsx'\n",
    "\n",
    "def create_df(path):\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "    df = df[['VP','Date_Time_last_action (MAX) / completed (SEMA3)','Teilnehmer Mattermost']]\n",
    "\n",
    "    #Generate placeholder values for missing columns \n",
    "    df[['fitbit_id','empatica_id']] = None\n",
    "    df['platform'] = 'infer'\n",
    "    df['label'] = df['VP']\n",
    "    df['end_date'] = None #df['Date_Time_last_action (MAX) / completed (SEMA3)']\n",
    "\n",
    "    #rename and order columns\n",
    "    df = df[['Teilnehmer Mattermost','fitbit_id','empatica_id','VP','platform','label','Date_Time_last_action (MAX) / completed (SEMA3)','end_date']]\n",
    "    df.columns = ['device_id','fitbit_id','empatica_id','pid','platform','label','start_date','end_date']\n",
    "\n",
    "    #drop NAs in pid column \n",
    "    df = df.dropna(subset=['pid'])\n",
    "    df = df.dropna(subset=['device_id'])\n",
    "\n",
    "    #Convert dtypes\n",
    "    df = df.astype({\"label\": int, \"pid\": int})\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], infer_datetime_format = True)\n",
    "    #df['start_date'] = df['start_date'].dt.round('D') #round to day, yields inaccurate results \n",
    "\n",
    "\n",
    "    #group by participant and get first and last date, put in last two columns \n",
    "    end_dates = df.groupby('pid')['start_date'].max().to_frame()\n",
    "    start_dates = df.groupby('pid')['start_date'].min().to_frame()\n",
    "\n",
    "\n",
    "    df = df.drop_duplicates(subset=['pid']) #delete duplicate rows \n",
    "\n",
    "    df = df.drop(['start_date','end_date'], axis = 1)\n",
    "\n",
    "    df = df.merge(start_dates, how = 'inner', on = ['pid'])\n",
    "    df = df.merge(end_dates, how = 'inner', on = ['pid'])\n",
    "\n",
    "    #rename columns\n",
    "    df.columns = ['device_id','fitbit_id','empatica_id','pid','platform','label','start_date','end_date']\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d998763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_b = create_df(GESAMTFILE_b)\n",
    "df_m = create_df(GESAMTFILE_m)\n",
    "df_p = create_df(GESAMTFILE_p)\n",
    "gesamt = pd.concat([df_b,df_m,df_p], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1d3f5648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>fitbit_id</th>\n",
       "      <th>empatica_id</th>\n",
       "      <th>pid</th>\n",
       "      <th>platform</th>\n",
       "      <th>label</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>453</td>\n",
       "      <td>infer</td>\n",
       "      <td>453</td>\n",
       "      <td>2021-09-04 12:24:59.999999</td>\n",
       "      <td>2021-09-17 18:35:00.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   device_id fitbit_id empatica_id  pid platform  label  \\\n",
       "76                None        None  453    infer    453   \n",
       "\n",
       "                   start_date                   end_date  \n",
       "76 2021-09-04 12:24:59.999999 2021-09-17 18:35:00.000004  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gesamt[[gesamt['device_id'].isin({''})]]\n",
    "gesamt.loc[gesamt['device_id']==' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2e954d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load min-max sensing intervals as extracted from the database (alternatively, use database method to get it)\n",
    "with open('/home/jmocel/trelium/OPTIMAX-sensing/alltimewindowspertable.pkl', 'rb') as f:\n",
    "   dizi = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c4e1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mappings import RECORD_MAP\n",
    "tot_interval = pd.DataFrame()\n",
    "\n",
    "for i in RECORD_MAP:\n",
    "    tabella =  RECORD_MAP[i]['target_table']\n",
    "    if tabella in {'APP_USAGE_STATS', 'PHONE_CALENDAR', 'PHONE_RADIO'}:\n",
    "        continue\n",
    "    intervals = pd.DataFrame(dizi[tabella], columns=['device_id', 'start','end'])\n",
    "    tot_interval = pd.concat([tot_interval, intervals], ignore_index=True)    \n",
    "\n",
    "base_dates = tot_interval.groupby('device_id')['start'].min().to_frame()\n",
    "end_dates = tot_interval.groupby('device_id')['end'].max().to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9098019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = base_dates.merge(end_dates, how='inner',on=['device_id'])\n",
    "minmax=minmax.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "36531850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note how dates for the participant with no name differ between gesamtfile and passive sensing database. Assume they are not the same participant \n",
    "res = [i for i in minmax['device_id'] if str(i)[-3:] != '-om']\n",
    "minmax[minmax['device_id'].isin({''})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ea11722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesamt['device_id'] = [i+'-om' for i in gesamt['device_id']]\n",
    "part_table = gesamt.loc[gesamt['device_id'].isin(minmax['device_id'])]\n",
    "part_table = part_table.merge(minmax, how = 'inner', on = ['device_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ff9a4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_table = part_table.drop(['start_date','end_date'], axis = 1)\n",
    "part_table.columns = ['device_id', 'fitbit_id', 'empatica_id', 'pid', 'platform', 'label', 'start_date', 'end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5917db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_table.to_csv('/home/jmocel/trelium/OPTIMAX-sensing/AllSensingParticipants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0ad9e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'102',\n",
       " '104',\n",
       " '124',\n",
       " '131',\n",
       " '134',\n",
       " '141',\n",
       " '149',\n",
       " '154',\n",
       " '166',\n",
       " '170',\n",
       " '181',\n",
       " '194',\n",
       " '201',\n",
       " '208',\n",
       " '230',\n",
       " '255',\n",
       " '261',\n",
       " '262',\n",
       " '263',\n",
       " '265',\n",
       " '273',\n",
       " '284',\n",
       " '310',\n",
       " '319',\n",
       " '326',\n",
       " '333',\n",
       " '355',\n",
       " '366',\n",
       " '369',\n",
       " '376',\n",
       " '383',\n",
       " '393',\n",
       " '400'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{str(i) for i in part_table['pid']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
